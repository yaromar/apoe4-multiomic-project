# WES_pipeline (Slurm + DSQ workflow)

This folder contains scripts for whole-exome sequencing (WES) preprocessing and
analysis on the Yale HPC cluster. All paths are cluster-specific and provided for documentation; users should adapt paths and module names to their local environment.

---

## DSQ execution model (parameters already validated)

Most of this pipeline uses **dSQ** to execute large numbers of file-level commands
as Slurm array jobs.

The **resource parameters are already fixed**, based on dry runs performed on the
largest FASTQ files in the dataset.

---

## DSQ parameters used

CPU count, walltime, maximum concurrent jobs, and array size parameters are
**hard-coded in each script** and should not be changed unless the underlying
data characteristics change.

The Slurm script generated by `dSQ` will typically include directives such as:

```bash
#SBATCH --array 0-1817%20
#SBATCH --output DSQ_results
#SBATCH --job-name dsq-joblist
#SBATCH -c 10
#SBATCH -t 10:00:00
```

## General workflow pattern

For most WES steps in this directory the scripts:
	1.	Generate a text file containing one command per input file (the joblist)
	2.	Use dSQ to convert the joblist into a Slurm array job

Then you submit the generated .slurm file with sbatch
